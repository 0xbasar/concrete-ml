{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-In Fully Connected Neural Network on MNIST \n",
    "\n",
    "In this notebook, we show how to train and evaluate a fully connected neural network on the MNIST classification problem using the Concrete-ML library, our open-source privacy-preserving machine learning framework based on fully homomorphic encryption (FHE).\n",
    "\n",
    "Using a built-in model, this example emphasizes on the API's ease-of-use by illustrating the few main steps needed to create an efficient inference-secured Neural Network classifier. Thanks to the internal implementation of Quantize Aware Training (QAT) techniques, this Concrete-ML `NeuralNetCLassifier` model reaches a high accuracy score. More information about QAT is available in the [QAT notebook](QuantizationAwareTraining.ipynb).\n",
    "\n",
    "More precisely, the model is trained on clear data and tested using FHE simulation.\n",
    "\n",
    "<!--- \n",
    "Add FHE execution when 2037 is done\n",
    "FIXME: https://github.com/zama-ai/concrete-ml-internal/issues/2307 \n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "\n",
    "We import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from concrete.numpy import Configuration\n",
    "from IPython.display import clear_output\n",
    "from joblib import Memory\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "\n",
    "from concrete.ml.sklearn import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "We download the train and test data sets from OpenML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn's fetch_openml method doesn't handle local cache:\n",
    "# https://github.com/scikit-learn/scikit-learn/issues/18783#issuecomment-723471498\n",
    "# This is a workaround that prevents downloading the data every time the notebook is ran\n",
    "memory = Memory(\"./data/MNIST\")\n",
    "fetch_openml_cached = memory.cache(fetch_openml)\n",
    "\n",
    "# Fetch the MNIST data set, with inputs already flattened\n",
    "mnist_dataset = fetch_openml_cached(\"mnist_784\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define max, mean and std values for the MNIST data set\n",
    "max_value = 255\n",
    "mean = 0.1307\n",
    "std = 0.3081\n",
    "\n",
    "# Normalize the training data\n",
    "data = (mnist_dataset.data) / max_value\n",
    "data = ((data - mean) / std).round(decimals=4)\n",
    "\n",
    "# Convert the inputs to float32 and targets to int64\n",
    "# FIXME: https://github.com/zama-ai/concrete-ml-internal/issues/2327\n",
    "data = data.astype(\"float32\")\n",
    "target = mnist_dataset.target.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 10000\n",
    "x_train, x_test = train_test_split(data, test_size=test_size, random_state=0)\n",
    "y_train, y_test = train_test_split(target, test_size=test_size, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model\n",
    "\n",
    "This step is easy to achieve as we use a built-in Fully Connected Neural Network. Only a few input parameters are needed:\n",
    "- `module__n_layers`: number of Fully Connected layers to use in the model\n",
    "- `module__n_w_bits` and `module__n_a_bits`: respectively the number of bits to use for quantizing the weight and input/activation values as the FHE can currently only compute integers. These numbers should not become too large as it can cause the compilation step to fail (see Compile section below)\n",
    "- `module__n_accum_bits`: The maximal allowed bit-width to target for intermediate accumulators. It is currently set to 15 as the actual maximum bit width reached during compilation can be up to one bit higher than this targeted value, in this case 16, which is the maximal value that Concrete-ML currently supports.\n",
    "-  `module__n_outputs`: Number of output classes\n",
    "- `module__n_hidden_neurons_multiplier`: A factor that is multiplied by the maximal number of active (non-zero weight) neurons for every layer. Default to 4 but set to 1 here in order to speed up all executions without changing the test accuracy by much. More detail in the qqn documentation. \n",
    "- `module__input_dim`: The inputs' shape\n",
    "- `module__activation_function`: The activation function to use\n",
    "- `max_epochs`: The number of epochs to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"module__n_layers\": 2,\n",
    "    \"module__n_w_bits\": 4,\n",
    "    \"module__n_a_bits\": 4,\n",
    "    \"module__n_accum_bits\": 15,\n",
    "    \"module__n_outputs\": 10,\n",
    "    \"module__n_hidden_neurons_multiplier\": 1,\n",
    "    \"module__input_dim\": x_train.shape[1],\n",
    "    \"module__activation_function\": nn.Sigmoid,\n",
    "    \"max_epochs\": 10,\n",
    "}\n",
    "\n",
    "model = NeuralNetClassifier(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "The fit method handles Pandas DataFrame as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X=x_train, y=y_train)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute predictions in the clear\n",
    "\n",
    "We then compute the accuracy score reached by the model when executed in the clear. It is important to understand that no FHE computations are done here. This step is not necessary but helps illustrate what results should we expect from the model. It is therefore used to demonstrate that FHE computations are exact, meaning the FHE accuracy score will exactly match this very one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of the clear model is 96.49%\n"
     ]
    }
   ],
   "source": [
    "y_preds_clear = model.predict(x_test)\n",
    "\n",
    "print(f\"The test accuracy of the clear model is {np.mean(y_preds_clear == y_test)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model with FHE Simulation\n",
    "\n",
    "A Concrete-ML model needs to be compiled on an inputset, usually the train set or one of its sub-set, before being able to predict. This step creates a FHE circuit, which essentially saves elements found in the model's inference (graph of operations, shapes, bit-width precisions, etc.) needed for the compiler when executing the predictions in FHE during the `predict` method. \n",
    "\n",
    "The maximum bit-width that can be reached by any values (inputs, weights, accumulators) in this circuit is currently 16-bits. If this limit is exceeded, the compilation fails and the user needs to change some of the model's parameters (e.g. decrease the number of quantization bits or decrease `module__n_accum_bits`). \n",
    "\n",
    "<!--- \n",
    "Make it compile in non-VL when 2037 is done\n",
    "FIXME: https://github.com/zama-ai/concrete-ml-internal/issues/2307 \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit of 12 bits (VL)\n"
     ]
    }
   ],
   "source": [
    "# Enable unsafe features in order to be able to simulate in FHE, through the use of the\n",
    "# Virtual Library (VL)\n",
    "configuration = Configuration(enable_unsafe_features=True)\n",
    "\n",
    "# Reduce the inputset's length to make the compilation time faster\n",
    "# Also convert it to a Numpy array as the compile method only handles this input type\n",
    "# FIXME: https://github.com/zama-ai/concrete-ml-internal/issues/1167\n",
    "inputset = x_train[:1000].to_numpy()\n",
    "fhe_circuit = model.compile(inputset, configuration=configuration, use_virtual_lib=True)\n",
    "\n",
    "# Print the circuit's maximum bit-width reached during compilation\n",
    "print(f\"Circuit of {fhe_circuit.graph.maximum_integer_bit_width()} bits (FHE simulation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute predictions with FHE simulation\n",
    "\n",
    "Now, we compute the accuracy score reached by the FHE model with FHE simulation. The accuracy score obtained by simulation is expected to be the same as the one obtained in FHE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy (with FHE simulation) of the FHE model is 96.49%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the Virtual Library\n",
    "y_preds_fhe = model.predict(x_test, execute_in_fhe=True)\n",
    "\n",
    "print(\n",
    "    \"The test accuracy (with FHE simulation) of the FHE model is\"\n",
    "    f\"{np.mean(y_preds_fhe == y_test)*100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute predictions in FHE\n",
    "\n",
    "Now, we compute the accuracy score reached by the FHE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add FHE prediction when 16b TLUs are available\n",
    "# FIXME: https://github.com/zama-ai/concrete-ml-internal/issues/2307"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we showed how to use a built-in Fully Connected Neural Network classifier on the MNIST data set using the Concrete-ML library in order to make its inference completely secure.\n",
    "\n",
    "Training, compiling and evaluation such a model is intuitive as our API follows most common Machine Learning APIs. In fact, only a few additional parameters related to quantization are requested, such as `module__n_w_bits`, `module__n_a_bits` or `module__n_accum_bits`. Thanks to the internal implementation of Quantize Aware Training (QAT) techniques, the Concrete-ML `NeuralNetCLassifier` model reached a high accuracy score.\n",
    "\n",
    "<!--- \n",
    "Add FHE executions times when 2037 is done\n",
    "FIXME: https://github.com/zama-ai/concrete-ml-internal/issues/2307 \n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 10800
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
