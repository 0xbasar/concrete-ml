{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Trees are a popular class of algorithm in Machine Learning. In this notebook we build a simple Decision Tree Classifier using `scikit-learn` to show that they can be executed homomorphically using Concrete Numpy.\n",
    "\n",
    "Converting a tree working over quantized data to its FHE equivalent takes only a few lines of code thanks to Concrete ML.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Use Case\n",
    "\n",
    "The use case is a spam classification task from OpenML you can find here: https://www.openml.org/d/44\n",
    "\n",
    "Some pre-extracted features (like some word frequencies) are provided as well as a class, `0` for a normal e-mail and `1` for spam, for 4601 samples.\n",
    "\n",
    "Let's first get the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features, classes = fetch_openml(data_id=44, as_frame=False, cache=True, return_X_y=True)\n",
    "classes = classes.astype(numpy.int64)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    classes,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use some sklearn cross validation tool to find the best hyper parameters for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 8, 'max_features': None, 'min_samples_leaf': 40, 'min_samples_split': 100}\n",
      "Best score: 0.7608810439720429\n"
     ]
    }
   ],
   "source": [
    "# Find best hyperparameters with cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from concrete.ml.sklearn import DecisionTreeClassifier as ConcreteDecisionTreeClassifier\n",
    "\n",
    "# List of hyperparameters to tune\n",
    "param_grid = {\n",
    "    \"max_features\": [None, \"auto\", \"sqrt\", \"log2\"],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 40, 60, 80, 100],\n",
    "    \"min_samples_split\": [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 40, 60, 80, 100],\n",
    "    \"max_depth\": [None, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 40, 60, 80, 100],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    ConcreteDecisionTreeClassifier(),\n",
    "    param_grid,\n",
    "    cv=10,\n",
    "    scoring=\"average_precision\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "gs_results = grid_search.fit(x_train, y_train)\n",
    "print(\"Best hyperparameters:\", gs_results.best_params_)\n",
    "print(\"Best score:\", gs_results.best_score_)\n",
    "\n",
    "# Build the model with best hyper parameters\n",
    "model = ConcreteDecisionTreeClassifier(\n",
    "    max_features=gs_results.best_params_[\"max_features\"],\n",
    "    min_samples_leaf=gs_results.best_params_[\"min_samples_leaf\"],\n",
    "    min_samples_split=gs_results.best_params_[\"min_samples_split\"],\n",
    "    max_depth=gs_results.best_params_[\"max_depth\"],\n",
    ")\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compute some metrics on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Compute average precision on test\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "print(\"Average precision-recall score: {0:0.2f}\".format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 691\n",
      "Number of spams in test samples: 304\n",
      "True Negative (legit mail well classified) rate: 0.9612403100775194\n",
      "False Positive (legit mail classified as spam) rate: 0.03875968992248062\n",
      "False Negative (spam mail classified as legit) rate: 0.21052631578947367\n",
      "True Positive (spam well classified) rate: 0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "# Show the confusion matrix on x_test\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "true_negative, false_positive, false_negative, true_positive = confusion_matrix(\n",
    "    y_test, y_pred, normalize=\"true\"\n",
    ").ravel()\n",
    "\n",
    "num_samples = len(y_test)\n",
    "num_spam = sum(y_test)\n",
    "\n",
    "print(f\"Number of test samples: {num_samples}\")\n",
    "print(f\"Number of spams in test samples: {num_spam}\")\n",
    "\n",
    "print(f\"True Negative (legit mail well classified) rate: {true_negative}\")\n",
    "print(f\"False Positive (legit mail classified as spam) rate: {false_positive}\")\n",
    "print(f\"False Negative (spam mail classified as legit) rate: {false_negative}\")\n",
    "print(f\"True Positive (spam well classified) rate: {true_positive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are ready to go in the FHE domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first compile the model with some data, here the training set\n",
    "model.compile(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict in FHE for a few examples\n",
    "y_pred_fhe = model.predict(x_test[:10], use_fhe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction FHE: [0 0 0 1 0 1 0 0 0 0]\n",
      "Prediction sklearn: [0 0 0 1 0 1 0 0 0 0]\n",
      "Prediction tensor: [0 0 0 1 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Check prediction FHE vs sklearn\n",
    "print(f\"Prediction FHE: {y_pred_fhe}\")\n",
    "print(f\"Prediction sklearn: {y_pred[:10]}\")\n",
    "\n",
    "# We can also check the prediction from the tensor version of the tree\n",
    "y_pred_tensor = model._predict_with_tensors(x_test[:10])\n",
    "print(f\"Prediction tensor: {y_pred_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 predictions are similar between the FHE model and the clear sklearn model.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"{numpy.sum(y_pred_fhe==y_pred[:10])}/\"\n",
    "    \"10 predictions are similar between the FHE model and the clear sklearn model.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Fully Homomorphic Decision trees are now in reach of any data scientist familiar with scikit-learn APIs."
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 10800
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
